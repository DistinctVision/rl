model:
  sequence_size: 1

  policy_net_layers: [256, 256]
  value_net_layers: [256, 256]
  dropout: 0.0

  models_path: '..\rl_output\ppo_11_05_2023__21_56_57\weights\ppocket_rocket_780.kpt'
  optimizer_path: '..\rl_output\ppo_11_05_2023__21_56_57\weights\opt_ppocket_rocket_780.kpt'
  
game:
  fps: 12

replays:
  data_folder: '..\rl_replays'
  max_readed_games: 5
  reread_games_every_n_step: 1000

rollout:
  observation_size: 43
  max_buffer_size: 8192
  calc_batch_size: 256
  discount_factor: 0.99
  gae_lambda: 0.95

training:
  lr: 3e-4
  n_epochs: 10
  
  batch_size: 256
  grad_norm: 0.5

  ppo:
    normalize_advantage: True
    clip_range: 0.2
    entropy_coef: 0.0
    value_function_coef: 0.5 

  output_folder: ../rl_output
  
  save:
    model_name: ppocket_rocket
    save_every_n_step: 5
    n_last_steps: 10
    target_metric: mean_reward
    target_op: '>'
    save_hist_every_n_step: 10
